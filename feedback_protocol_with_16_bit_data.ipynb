{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1722101709/Internship/blob/feedback_protocol_with_16-bit-data/feedback_protocol_with_16_bit_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2uWVQ8od1Tgc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "from collections import deque\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 16 # no of bits"
      ],
      "metadata": {
        "id": "odQQszgwFLoB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ELPLlfjp-zji"
      },
      "outputs": [],
      "source": [
        "class OUNoise(object): # noise class\n",
        "    def __init__(self, action_space, mu=0.0, theta=0.15, max_sigma=0.3, min_sigma=0.3, decay_period=100000):\n",
        "        self.mu           = mu\n",
        "        self.theta        = theta\n",
        "        self.sigma        = max_sigma\n",
        "        self.max_sigma    = max_sigma\n",
        "        self.min_sigma    = min_sigma\n",
        "        self.decay_period = decay_period\n",
        "        self.action_dim   = action_space.shape[0]\n",
        "        self.low          = action_space.low\n",
        "        self.high         = action_space.high\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self): # resetting the state\n",
        "        self.state = np.ones(self.action_dim) * self.mu\n",
        "        \n",
        "    def evolve_state(self): # exploring the next state\n",
        "        x  = self.state\n",
        "        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(self.action_dim)\n",
        "        self.state = x + dx\n",
        "        return self.state\n",
        "    \n",
        "    def get_action(self, action, t=0): # get action for the current state\n",
        "        ou_state = self.evolve_state()\n",
        "        self.sigma = self.max_sigma - (self.max_sigma - self.min_sigma) * min(1.0, t / self.decay_period)\n",
        "        return np.clip(action + ou_state, self.low, self.high)\n",
        "\n",
        "\n",
        "        \n",
        "# memory class to store the experiences\n",
        "class Memory:\n",
        "    def __init__(self, max_size): # initializing memory with max_size\n",
        "        self.max_size = max_size\n",
        "        self.buffer = deque(maxlen=max_size)\n",
        "    \n",
        "    def push(self, state, action, reward, next_state, done): # push method to add experience into the memory\n",
        "        experience = (state, action, np.array([reward]), next_state, done)\n",
        "        self.buffer.append(experience)\n",
        "\n",
        "    def sample(self, batch_size): # seperating the elements in the experience into  seperate lists\n",
        "        state_batch = [] # states\n",
        "        action_batch = [] # actions\n",
        "        reward_batch = [] # rewards\n",
        "        next_state_batch = [] # next state\n",
        "        done_batch = [] # is_done\n",
        "\n",
        "        batch = random.sample(self.buffer, batch_size)\n",
        "\n",
        "        for experience in batch:\n",
        "            state, action, reward, next_state, done = experience\n",
        "            state_batch.append(state)\n",
        "            action_batch.append(action)\n",
        "            reward_batch.append(reward)\n",
        "            next_state_batch.append(next_state)\n",
        "            done_batch.append(done)\n",
        "        \n",
        "        return state_batch, action_batch, reward_batch, next_state_batch, done_batch\n",
        "\n",
        "    def __len__(self): # to get the size of the memory filled with experiences\n",
        "        return len(self.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8_HsRP3x-2w9"
      },
      "outputs": [],
      "source": [
        "# importing necessary modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torch.autograd\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class Critic(nn.Module): # critic class to implement the critic network \n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size): # initializing the critic network\n",
        "        super(Critic, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, state, action): # forward propogation i.e., input to the input layer => output from the output layer\n",
        "\n",
        "        x = torch.cat([state, action], 1)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Actor(nn.Module): # Actor class to implement the Actor Network\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, learning_rate = 3e-4): # initializing the Actor network\n",
        "        super(Actor, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear3 = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, state): # forward propogation in Actor network with input\n",
        "\n",
        "        x = F.relu(self.linear1(state))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = torch.tanh(self.linear3(x))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qLB_UGUS-7OI"
      },
      "outputs": [],
      "source": [
        "# importing necessary modules \n",
        "import torch\n",
        "import torch.autograd\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class DDPGagent: # agent class(Deep Deterministic Policy Gradient)\n",
        "\n",
        "    # initilaizations\n",
        "    def __init__(self, env, hidden_size=256, actor_learning_rate=1e-4, critic_learning_rate=1e-3, gamma=0.99, tau=1e-2, max_memory_size=50000):\n",
        "        # Parameters\n",
        "        self.num_states = env.observation_space.shape[0] # number of states\n",
        "        self.num_actions = env.action_space.shape[0] # no of actions\n",
        "        self.gamma = gamma\n",
        "        self.tau = tau\n",
        "\n",
        "        # Networks\n",
        "        self.actor = Actor(self.num_states, hidden_size, self.num_actions) # actor network\n",
        "        self.actor_target = Actor(self.num_states, hidden_size, self.num_actions) # actor target network\n",
        "        self.critic = Critic(self.num_states + self.num_actions, hidden_size, self.num_actions) # critic network\n",
        "        self.critic_target = Critic(self.num_states + self.num_actions, hidden_size, self.num_actions) # critic target network\n",
        "\n",
        "        for target_param, param in zip(self.actor_target.parameters(), self.actor.parameters()):\n",
        "            target_param.data.copy_(param.data)\n",
        "\n",
        "        for target_param, param in zip(self.critic_target.parameters(), self.critic.parameters()):\n",
        "            target_param.data.copy_(param.data)\n",
        "        \n",
        "        # Training\n",
        "        self.memory = Memory(max_memory_size) # initialize the memory  \n",
        "        self.critic_criterion  = nn.MSELoss() # loss function\n",
        "        self.actor_optimizer  = optim.Adam(self.actor.parameters(), lr=actor_learning_rate) # optimizers for actor network\n",
        "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=critic_learning_rate) # optimizers for critic network\n",
        "    \n",
        "    def get_action(self, state): # to get the action for the state by passing state as input to the actor network\n",
        "        state = Variable(torch.from_numpy(state).float().unsqueeze(0))\n",
        "        action = self.actor.forward(state)\n",
        "        action = action.detach().numpy()[0,0]\n",
        "        return action\n",
        "    \n",
        "    def update(self, batch_size): # updating the sampling after batch_size iterations\n",
        "        states, actions, rewards, next_states, _ = self.memory.sample(batch_size)\n",
        "        states = torch.FloatTensor(states)\n",
        "        actions = torch.FloatTensor(actions)\n",
        "        rewards = torch.FloatTensor(rewards)\n",
        "        next_states = torch.FloatTensor(next_states)\n",
        "    \n",
        "        # Critic loss        \n",
        "        Qvals = self.critic.forward(states, actions)\n",
        "        next_actions = self.actor_target.forward(next_states)\n",
        "        next_Q = self.critic_target.forward(next_states, next_actions.detach())\n",
        "        Qprime = rewards + self.gamma * next_Q\n",
        "        critic_loss = self.critic_criterion(Qvals, Qprime)\n",
        "\n",
        "        # Actor loss\n",
        "        policy_loss = -self.critic.forward(states, self.actor.forward(states)).mean()\n",
        "        \n",
        "        # update networks\n",
        "        self.actor_optimizer.zero_grad() # actor network\n",
        "        policy_loss.backward()\n",
        "        self.actor_optimizer.step()\n",
        "\n",
        "        self.critic_optimizer.zero_grad() # critic network\n",
        "        critic_loss.backward() \n",
        "        self.critic_optimizer.step()\n",
        "\n",
        "        # update target networks \n",
        "        for target_param, param in zip(self.actor_target.parameters(), self.actor.parameters()):\n",
        "            target_param.data.copy_(param.data * self.tau + target_param.data * (1.0 - self.tau))\n",
        "       \n",
        "        for target_param, param in zip(self.critic_target.parameters(), self.critic.parameters()):\n",
        "            target_param.data.copy_(param.data * self.tau + target_param.data * (1.0 - self.tau))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zE84Q12h_D5D"
      },
      "outputs": [],
      "source": [
        "# importing modules\n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "from sklearn.decomposition import PCA\n",
        "# Environment\n",
        "class Environment(Env):\n",
        "\n",
        "    def __init__(self): # initializing environment\n",
        "        self.action_space = Box(low = np.array([-1]), high = np.array([1]), dtype=float)\n",
        "        self.observation_space = Box(low = np.array([-1]), high = np.array([1]), dtype=float)\n",
        "        self.state = np.round(np.random.random(1), decimals=2)\n",
        "        self.n = 2**n\n",
        "        self.data = self.get_data(self.n)\n",
        "        self.iter = 0\n",
        "    def step(self, action): # taking actions on environment\n",
        "\n",
        "        reward = abs(action)\n",
        "        done, next_state = True if self.iter  == self.n-2 else  False, np.array([self.data[self.iter+1]])\n",
        "        self.state = next_state\n",
        "        self.iter += 1\n",
        "        return self.state,reward,done,{}\n",
        "    def get_data(self,n):\n",
        "        x = []\n",
        "        for i in range(n):\n",
        "            pattern = '{0:0'+str(n)+'b}'\n",
        "            y = pattern.format(random.randint(1,n))\n",
        "            x.append([ord(j)-ord('0') for j in y])\n",
        "        x = pd.DataFrame(x)\n",
        "        c = len(x.columns)\n",
        "        if c == 17:del x[n]\n",
        "        x_scaler = StandardScaler().fit_transform(x) # Scaling\n",
        "        x_normalize = pd.DataFrame(normalize(x_scaler)) # normalizing\n",
        "        \n",
        "        x_pca = pd.DataFrame(PCA(n_components=1).fit_transform(x_normalize)) # applying PCA and storing the result in dataframe\n",
        "\n",
        "        return list(x_pca[0])\n",
        "    def reset(self): # reset the environment\n",
        "        self.__init__()\n",
        "        return self.state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKmcyP_4QPwZ",
        "outputId": "09d4257c-c8ed-4b88-a841-d4ef505ca141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode: 1, reward: 32821.24, average _reward: 32821.23881686684 \n",
            "\n",
            "episode: 2, reward: 32669.24, average _reward: 32745.237521462055 \n",
            "\n",
            "episode: 3, reward: 32796.85, average _reward: 32762.440797805553 \n",
            "\n",
            "episode: 4, reward: 32930.75, average _reward: 32804.51708472024 \n",
            "\n",
            "episode: 5, reward: 32602.43, average _reward: 32764.09914727183 \n",
            "\n",
            "episode: 6, reward: 32752.11, average _reward: 32762.101331942522 \n",
            "\n",
            "episode: 7, reward: 32685.09, average _reward: 32751.099568689246 \n",
            "\n",
            "episode: 8, reward: 32765.6, average _reward: 32752.912140001165 \n",
            "\n",
            "episode: 9, reward: 32798.17, average _reward: 32757.94074683526 \n",
            "\n",
            "episode: 10, reward: 32578.55, average _reward: 32740.002128137225 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#importing modules\n",
        "import sys\n",
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "env = Environment() # creating environment\n",
        "\n",
        "agent = DDPGagent(env) # agent\n",
        "noise = OUNoise(env.action_space) # noise class object\n",
        "batch_size = 2 \n",
        "rewards = []\n",
        "avg_rewards = []\n",
        "episodes = 10 # no of episodes\n",
        "steps = 2**n-1 # no of steps in an episode\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()\n",
        "    noise.reset()\n",
        "    episode_reward = 0\n",
        "    for step in range(steps):\n",
        "        action = random.uniform(-1,1) # random action\n",
        "        new_state, reward, done, _ = env.step(action) # apply action on the environment\n",
        "        \n",
        "        state = new_state\n",
        "        episode_reward += reward\n",
        "        if done: # if environment was explored fully then, stop\n",
        "            break\n",
        " \n",
        "    rewards.append(episode_reward)\n",
        "    avg_rewards.append(np.mean(rewards[-10:]))\n",
        "    # print total reward for the episode and average_reward per episode\n",
        "    print(\"episode: {}, reward: {}, average _reward: {} \\n\".format(episode+1, np.round(episode_reward, decimals=2), np.mean(rewards[-10:])))\n",
        "without_feedback_rewards = rewards\n",
        "without_feedback_avg_rewards = avg_rewards\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_0vXX_e_I2A",
        "outputId": "86e570e8-bbf5-4134-f977-0ecb58fe45ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode: 1, reward: [51735.49], average _reward: 51735.491646213675 \n",
            "\n",
            "episode: 2, reward: [51675.93], average _reward: 51705.71092022459 \n",
            "\n",
            "episode: 3, reward: [51752.38], average _reward: 51721.26688520432 \n",
            "\n",
            "episode: 4, reward: [51693.35], average _reward: 51714.28884552134 \n",
            "\n",
            "episode: 5, reward: [51675.45], average _reward: 51706.521204447796 \n",
            "\n",
            "episode: 6, reward: [51442.64], average _reward: 51662.54090822672 \n",
            "\n",
            "episode: 7, reward: [51742.37], average _reward: 51673.94471259007 \n",
            "\n",
            "episode: 8, reward: [52111.42], average _reward: 51728.62906650451 \n",
            "\n",
            "episode: 9, reward: [51266.18], average _reward: 51677.24577462014 \n",
            "\n",
            "episode: 10, reward: [51448.11], average _reward: 51654.331922859754 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#importing modules\n",
        "import sys\n",
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "env = Environment() # creating environment\n",
        "\n",
        "agent = DDPGagent(env) # agent\n",
        "noise = OUNoise(env.action_space) # noise class object\n",
        "batch_size = 2 \n",
        "rewards = []\n",
        "avg_rewards = []\n",
        "episodes = 10 # no of episodes\n",
        "steps = 2**n-1 # no of steps in an episode\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()\n",
        "    noise.reset()\n",
        "    episode_reward = 0\n",
        "    for step in range(steps):\n",
        "        action = agent.get_action(state) # get action from Agent\n",
        "        action = noise.get_action(action, step) # add noise to the action\n",
        "        new_state, reward, done, _ = env.step(action) # apply action on the environment\n",
        "        agent.memory.push(state, action, reward, new_state, done) # store the experience in the memory\n",
        "        \n",
        "        if len(agent.memory) > batch_size: # update the sampling after batch_size iterations\n",
        "            agent.update(batch_size)\n",
        "        \n",
        "        state = new_state\n",
        "        episode_reward += reward\n",
        "        if done: # if environment was explored fully then, stop\n",
        "            break\n",
        " \n",
        "    rewards.append(episode_reward)\n",
        "    avg_rewards.append(np.mean(rewards[-10:]))\n",
        "    # print total reward for the episode and average_reward per episode\n",
        "    print(\"episode: {}, reward: {}, average_reward: {} \\n\".format(episode+1, np.round(episode_reward, decimals=2), np.mean(rewards[-10:])))\n",
        "with_feedback_rewards = rewards\n",
        "with_feedback_avg_rewards = avg_rewards"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "without_feedback_avg_rewards"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi4wX8qvGMhi",
        "outputId": "dd455b29-132d-43a5-88bd-3a3facee2994"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[32821.23881686684,\n",
              " 32745.237521462055,\n",
              " 32762.440797805553,\n",
              " 32804.51708472024,\n",
              " 32764.09914727183,\n",
              " 32762.101331942522,\n",
              " 32751.099568689246,\n",
              " 32752.912140001165,\n",
              " 32757.94074683526,\n",
              " 32740.002128137225]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with_feedback_avg_rewards"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5NQvZUXGQUH",
        "outputId": "75c52a54-d65d-46ae-c0d3-4f9eebd6eace"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[51735.491646213675,\n",
              " 51705.71092022459,\n",
              " 51721.26688520432,\n",
              " 51714.28884552134,\n",
              " 51706.521204447796,\n",
              " 51662.54090822672,\n",
              " 51673.94471259007,\n",
              " 51728.62906650451,\n",
              " 51677.24577462014,\n",
              " 51654.331922859754]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GtnmJLu0_Jwz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f2ec5422-d720-4103-b4c7-328a5b4fd2a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import matplotlib as mpl\n",
        "plt.plot(with_feedback_avg_rewards,'g',linewidth=3)\n",
        "plt.plot(without_feedback_avg_rewards,'r',linewidth=1.5)\n",
        "plt.plot()\n",
        "plt.legend([\"with feedback\", \"without feedback\"], loc =\"center\")\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylabel('Average Reward')\n",
        "plt.title('average rewards w.r.t episodes')\n",
        "plt.style.use('dark_background')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "feedback_protocol_with_16-bit_data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNT+hAe/LeGEkKC/8e9eo89",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}